{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "637cc60d"
      },
      "source": [
        "# Extracting text from HTML web pages\n",
        "\n",
        "by Koenraad De Smedt at UiB"
      ],
      "id": "637cc60d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lME03Clev2yx"
      },
      "source": [
        "---\n",
        "HTML (hypertext markup language) is the standard format for webpages. It has codes for headings, paragraphs, lists, etc. \n",
        "\n",
        "This notebook shows how to:\n",
        "1.  Extract plain text from HTML on webpages\n",
        "2.  Inspect the data access and extraction process at every step.\n",
        "\n",
        "Note: There is also a package [textract](https://textract.readthedocs.io/en/stable/python_package.html) which provides text extraction from many types of files, but this package is complex and beyond the scope of the present course.\n",
        "\n",
        "---"
      ],
      "id": "lME03Clev2yx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to import a module that can request access to a webpage based on its URL."
      ],
      "metadata": {
        "id": "WidGnw6_Zvdu"
      },
      "id": "WidGnw6_Zvdu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHlJrSVxzkVt"
      },
      "source": [
        "import requests"
      ],
      "id": "hHlJrSVxzkVt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEaTzQWozzri"
      },
      "source": [
        "The following is an example of a webpage with usable html. Also open this URL in a browser window to see what the page looks like. We are interested in extracting the text in normal paragraphs.\n"
      ],
      "id": "FEaTzQWozzri"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijASuzpKQyGI"
      },
      "source": [
        "chess_url = 'https://en.wikipedia.org/wiki/Chess'"
      ],
      "id": "ijASuzpKQyGI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IVDS5QXQ5LA"
      },
      "source": [
        "Open the webpage and get the content. The `b` in front of the string indicates that it is a string of raw bytes."
      ],
      "id": "-IVDS5QXQ5LA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDuV4HMqz84a"
      },
      "source": [
        "chess_html = requests.get(chess_url).content\n",
        "print(chess_html[:125])"
      ],
      "id": "dDuV4HMqz84a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGTruIRZCoZi"
      },
      "source": [
        "We see that the content is HTML. In order to get plain text out of the HTML, we need the `bs4` module (Beautiful Soup)."
      ],
      "id": "TGTruIRZCoZi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqipcjKWQdA3"
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "id": "JqipcjKWQdA3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlSZAqC00BF5"
      },
      "source": [
        "We are interested in the text contained in paragraphs, indicated with `<p>` tags. First, we use the `html.parser` to parse the html, then we find all paragaphraphs in the parsed html. Optionally print the number of paragraphs for information, and print the first few of them.\n",
        "\n",
        "(Note: not all html has paragraphs. If the content is a table, for instance, we may need to find all `td` elements instead.)\n"
      ],
      "id": "YlSZAqC00BF5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bobneuzO1olh"
      },
      "source": [
        "parsed_html = BeautifulSoup(chess_html, 'html.parser')\n",
        "paragraphs = parsed_html.find_all('p')\n",
        "print(len(paragraphs), 'paragraphs were extracted.')\n",
        "print(paragraphs[:4])"
      ],
      "id": "bobneuzO1olh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, if you know that some paragraphs are not relevant, you can skip them."
      ],
      "metadata": {
        "id": "PQSmvojtfSgJ"
      },
      "id": "PQSmvojtfSgJ"
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs = paragraphs[2:]\n",
        "print(paragraphs[:4])"
      ],
      "metadata": {
        "id": "Tab1FTjSfAe5"
      },
      "id": "Tab1FTjSfAe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOk4F2Jn1pDq"
      },
      "source": [
        "Next, concatenate the plain text in all the paragraphs together in a string. Print its length and the first thousand characters."
      ],
      "id": "hOk4F2Jn1pDq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IUYbEr90Iu_"
      },
      "source": [
        "chess_text = ''.join([node.text for node in paragraphs]).strip()\n",
        "print('Text is', len(chess_text), 'characters long.\\n')\n",
        "print(chess_text[:1000])"
      ],
      "id": "_IUYbEr90Iu_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_NUBBE32gdw"
      },
      "source": [
        "Voil√†! Now you have plain text that you can process further. Let's tokenize and compute the frequencies of the most common words."
      ],
      "id": "9_NUBBE32gdw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thLl1oifX4bP"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, FreqDist"
      ],
      "id": "thLl1oifX4bP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es8r25j02skO"
      },
      "source": [
        "chess_tokens = word_tokenize(chess_text.casefold())\n",
        "print(len(chess_tokens), 'tokens were found.')\n",
        "frequencies = FreqDist(chess_tokens)\n",
        "frequencies.most_common(20)"
      ],
      "id": "es8r25j02skO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjWFP6BuPNil"
      },
      "source": [
        "We can plot some counts. First we import the pyplot module."
      ],
      "id": "CjWFP6BuPNil"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz_-AwSNPRnP"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "id": "wz_-AwSNPRnP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik0zZlpBPSMw"
      },
      "source": [
        "Then we make a vector of the frequencies and make a dot plot. Notice what happens when you uncomment the line that says the *y* scale should be logarithmic."
      ],
      "id": "Ik0zZlpBPSMw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AU2JkqnO34L"
      },
      "source": [
        "freq_counts = [count for word, count in frequencies.most_common(500)]\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(freq_counts, '.')\n",
        "#plt.yscale('log')\n",
        "plt.title('Word frequency counts in Chess article')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Index')\n",
        "plt.show()"
      ],
      "id": "1AU2JkqnO34L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj1hh35D7Aid"
      },
      "source": [
        "Let's do some n-grams as well. The result is a generator. With the `next` function we can produce the next item from the generator."
      ],
      "id": "sj1hh35D7Aid"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arT0zbwuYUO6"
      },
      "source": [
        "from nltk.util import ngrams"
      ],
      "id": "arT0zbwuYUO6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV2w2TuO57eP"
      },
      "source": [
        "ng3 = ngrams(chess_tokens, 3)\n",
        "for i in range(12):\n",
        "  print(next(ng3))"
      ],
      "id": "XV2w2TuO57eP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0T6WLoJ_QEE"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "Put things together and make a function to extract plain text from html. Define a function `get_web_text` with three arguments: \n",
        "\n",
        "1.   a string representing a url to a webpage assumed to contain html.\n",
        "2.   a tag (default is *p*)\n",
        "\n",
        "The function should return a string with the plain text in all on the website (don't forget to use `return`). Also print the number of characters read."
      ],
      "id": "u0T6WLoJ_QEE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l17szIF_kFw"
      },
      "source": [
        "# Write your function here.\n",
        "def get_text_from_webpage(url, tag='p'):\n",
        "  ..."
      ],
      "id": "6l17szIF_kFw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohUvx1Ue_xQG"
      },
      "source": [
        "# This is a test of your function. Run this cell after defining your function.\n",
        "tennis_url = 'https://en.wikipedia.org/wiki/Tennis'\n",
        "tennis_text = get_text_from_webpage(tennis_url)\n",
        "print(tennis_text[:150])"
      ],
      "id": "ohUvx1Ue_xQG",
      "execution_count": null,
      "outputs": []
    }
  ]
}